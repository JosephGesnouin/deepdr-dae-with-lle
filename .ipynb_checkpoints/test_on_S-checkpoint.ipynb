{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist, fashion_mnist\n",
    "import pandas as pd\n",
    "from keras.layers import Input, Dense, concatenate \n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from keras import objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "train_images = train_images.astype('float32') / 255.\n",
    "train_images = train_images.reshape((len(x_train), np.prod(train_images.shape[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottle = pd.read_csv(\"result_mnist/l2_n15/bottlneck.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lle = LLEC(n_components=5, n_neighbors=15)\n",
    "S = lle.fit_W(bottle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdotB = np.dot(S, bottle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3732480066378144\n",
      "0.5098031962030086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yannis/.local/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:844: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=10).fit(sdotB)\n",
    "print(adjusted_rand_score(y_train, kmeans.labels_))\n",
    "print(normalized_mutual_info_score(y_train, kmeans.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = KernelPCA(n_components=2, kernel='poly')\n",
    "X_transformed = transformer.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import eye as speye\n",
    "from scipy.sparse.csgraph import laplacian\n",
    "from sklearn.manifold.locally_linear import (\n",
    "    barycenter_kneighbors_graph, null_space, LocallyLinearEmbedding)\n",
    "from sklearn.metrics.pairwise import pairwise_distances, rbf_kernel\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from scipy.linalg import eigh, svd, qr, solve\n",
    "from scipy.sparse import eye, csr_matrix\n",
    "from scipy.sparse.linalg import eigsh\n",
    "\n",
    "\n",
    "class LLEC(LocallyLinearEmbedding):\n",
    "    def __init__(self, n_neighbors=5, n_components=2, reg=1E-3,\n",
    "                 eigen_solver='auto', tol=1E-6, max_iter=100,\n",
    "                 method='standard', hessian_tol=1E-4, modified_tol=1E-12,\n",
    "                 neighbors_algorithm='auto', random_state=None, n_jobs=None):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.n_components = n_components\n",
    "        self.reg = reg\n",
    "        self.eigen_solver = eigen_solver\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "        self.method = method\n",
    "        self.hessian_tol = hessian_tol\n",
    "        self.modified_tol = modified_tol\n",
    "        self.random_state = random_state\n",
    "        self.neighbors_algorithm = neighbors_algorithm\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        self._fit_transform(X)\n",
    "        return self.embedding_\n",
    "    \n",
    "    def fit_W(self, X):\n",
    "        self._fit_transform(X)\n",
    "        return self.W.toarray()\n",
    "    \n",
    "    def _fit_transform(self, X):\n",
    "        self.nbrs_ = NearestNeighbors(self.n_neighbors,\n",
    "                                      algorithm=self.neighbors_algorithm,\n",
    "                                      n_jobs=self.n_jobs)\n",
    "\n",
    "        random_state = self.random_state\n",
    "        self.nbrs_.fit(X)\n",
    "        self.W = \\\n",
    "            locally_linear_embedding(\n",
    "                self.nbrs_, self.n_neighbors, self.n_components,\n",
    "                eigen_solver=self.eigen_solver, tol=self.tol,\n",
    "                max_iter=self.max_iter, method=self.method,\n",
    "                hessian_tol=self.hessian_tol, modified_tol=self.modified_tol,\n",
    "                random_state=random_state, reg=self.reg, n_jobs=self.n_jobs)\n",
    "\n",
    "def locally_linear_embedding(\n",
    "        X, n_neighbors, n_components, reg=1e-3, eigen_solver='auto', tol=1e-6,\n",
    "        max_iter=100, method='standard', hessian_tol=1E-4, modified_tol=1E-12,\n",
    "        random_state=None, n_jobs=None):\n",
    "    \n",
    "    if eigen_solver not in ('auto', 'arpack', 'dense'):\n",
    "        raise ValueError(\"unrecognized eigen_solver '%s'\" % eigen_solver)\n",
    "\n",
    "    if method not in ('standard', 'hessian', 'modified', 'ltsa'):\n",
    "        raise ValueError(\"unrecognized method '%s'\" % method)\n",
    "\n",
    "    nbrs = NearestNeighbors(n_neighbors=n_neighbors + 1, n_jobs=n_jobs)\n",
    "    nbrs.fit(X)\n",
    "    X = nbrs._fit_X\n",
    "\n",
    "    N, d_in = X.shape\n",
    "\n",
    "    if n_components > d_in:\n",
    "        raise ValueError(\"output dimension must be less than or equal \"\n",
    "                         \"to input dimension\")\n",
    "    if n_neighbors >= N:\n",
    "        raise ValueError(\n",
    "            \"Expected n_neighbors <= n_samples, \"\n",
    "            \" but n_samples = %d, n_neighbors = %d\" %\n",
    "            (N, n_neighbors)\n",
    "        )\n",
    "\n",
    "    if n_neighbors <= 0:\n",
    "        raise ValueError(\"n_neighbors must be positive\")\n",
    "\n",
    "    M_sparse = (eigen_solver != 'dense')\n",
    "\n",
    "    if method == 'standard':\n",
    "        W = barycenter_kneighbors_graph(nbrs, n_neighbors=n_neighbors, reg=reg, n_jobs=1)\n",
    "\n",
    "    \n",
    "        if M_sparse:\n",
    "            M = eye(*W.shape, format=W.format) - W\n",
    "            M = (M.T * M).tocsr()\n",
    "        else:\n",
    "            M = (W.T * W - W.T - W).toarray()\n",
    "            M.flat[::M.shape[0] + 1] += 1  # W = W - I = W - I\n",
    "\n",
    "    elif method == 'hessian':\n",
    "        dp = n_components * (n_components + 1) // 2\n",
    "\n",
    "        if n_neighbors <= n_components + dp:\n",
    "            raise ValueError(\"for method='hessian', n_neighbors must be \"\n",
    "                             \"greater than \"\n",
    "                             \"[n_components * (n_components + 3) / 2]\")\n",
    "\n",
    "        neighbors = nbrs.kneighbors(X, n_neighbors=n_neighbors + 1,\n",
    "                                    return_distance=False)\n",
    "        neighbors = neighbors[:, 1:]\n",
    "\n",
    "        Yi = np.empty((n_neighbors, 1 + n_components + dp), dtype=np.float64)\n",
    "        Yi[:, 0] = 1\n",
    "\n",
    "        M = np.zeros((N, N), dtype=np.float64)\n",
    "\n",
    "        use_svd = (n_neighbors > d_in)\n",
    "\n",
    "        for i in range(N):\n",
    "            Gi = X[neighbors[i]]\n",
    "            Gi -= Gi.mean(0)\n",
    "\n",
    "            # build Hessian estimator\n",
    "            if use_svd:\n",
    "                U = svd(Gi, full_matrices=0)[0]\n",
    "            else:\n",
    "                Ci = np.dot(Gi, Gi.T)\n",
    "                U = eigh(Ci)[1][:, ::-1]\n",
    "\n",
    "            Yi[:, 1:1 + n_components] = U[:, :n_components]\n",
    "\n",
    "            j = 1 + n_components\n",
    "            for k in range(n_components):\n",
    "                Yi[:, j:j + n_components - k] = (U[:, k:k + 1] *\n",
    "                                                 U[:, k:n_components])\n",
    "                j += n_components - k\n",
    "\n",
    "            Q, R = qr(Yi)\n",
    "\n",
    "            w = Q[:, n_components + 1:]\n",
    "            S = w.sum(0)\n",
    "\n",
    "            S[np.where(abs(S) < hessian_tol)] = 1\n",
    "            w /= S\n",
    "\n",
    "            nbrs_x, nbrs_y = np.meshgrid(neighbors[i], neighbors[i])\n",
    "            M[nbrs_x, nbrs_y] += np.dot(w, w.T)\n",
    "\n",
    "        if M_sparse:\n",
    "            M = csr_matrix(M)\n",
    "\n",
    "    elif method == 'modified':\n",
    "        if n_neighbors < n_components:\n",
    "            raise ValueError(\"modified LLE requires \"\n",
    "                             \"n_neighbors >= n_components\")\n",
    "\n",
    "        neighbors = nbrs.kneighbors(X, n_neighbors=n_neighbors + 1,\n",
    "                                    return_distance=False)\n",
    "        neighbors = neighbors[:, 1:]\n",
    "\n",
    "        # find the eigenvectors and eigenvalues of each local covariance\n",
    "        # matrix. We want V[i] to be a [n_neighbors x n_neighbors] matrix,\n",
    "        # where the columns are eigenvectors\n",
    "        V = np.zeros((N, n_neighbors, n_neighbors))\n",
    "        nev = min(d_in, n_neighbors)\n",
    "        evals = np.zeros([N, nev])\n",
    "\n",
    "        # choose the most efficient way to find the eigenvectors\n",
    "        use_svd = (n_neighbors > d_in)\n",
    "\n",
    "        if use_svd:\n",
    "            for i in range(N):\n",
    "                X_nbrs = X[neighbors[i]] - X[i]\n",
    "                V[i], evals[i], _ = svd(X_nbrs,\n",
    "                                        full_matrices=True)\n",
    "            evals **= 2\n",
    "        else:\n",
    "            for i in range(N):\n",
    "                X_nbrs = X[neighbors[i]] - X[i]\n",
    "                C_nbrs = np.dot(X_nbrs, X_nbrs.T)\n",
    "                evi, vi = eigh(C_nbrs)\n",
    "                evals[i] = evi[::-1]\n",
    "                V[i] = vi[:, ::-1]\n",
    "\n",
    "        # find regularized weights: this is like normal LLE.\n",
    "        # because we've already computed the SVD of each covariance matrix,\n",
    "        # it's faster to use this rather than np.linalg.solve\n",
    "        reg = 1E-3 * evals.sum(1)\n",
    "\n",
    "        tmp = np.dot(V.transpose(0, 2, 1), np.ones(n_neighbors))\n",
    "        tmp[:, :nev] /= evals + reg[:, None]\n",
    "        tmp[:, nev:] /= reg[:, None]\n",
    "\n",
    "        w_reg = np.zeros((N, n_neighbors))\n",
    "        for i in range(N):\n",
    "            w_reg[i] = np.dot(V[i], tmp[i])\n",
    "        w_reg /= w_reg.sum(1)[:, None]\n",
    "\n",
    "        # calculate eta: the median of the ratio of small to large eigenvalues\n",
    "        # across the points.  This is used to determine s_i, below\n",
    "        rho = evals[:, n_components:].sum(1) / evals[:, :n_components].sum(1)\n",
    "        eta = np.median(rho)\n",
    "\n",
    "        # find s_i, the size of the \"almost null space\" for each point:\n",
    "        # this is the size of the largest set of eigenvalues\n",
    "        # such that Sum[v; v in set]/Sum[v; v not in set] < eta\n",
    "        s_range = np.zeros(N, dtype=int)\n",
    "        evals_cumsum = stable_cumsum(evals, 1)\n",
    "        eta_range = evals_cumsum[:, -1:] / evals_cumsum[:, :-1] - 1\n",
    "        for i in range(N):\n",
    "            s_range[i] = np.searchsorted(eta_range[i, ::-1], eta)\n",
    "        s_range += n_neighbors - nev  # number of zero eigenvalues\n",
    "\n",
    "        # Now calculate M.\n",
    "        # This is the [N x N] matrix whose null space is the desired embedding\n",
    "        M = np.zeros((N, N), dtype=np.float64)\n",
    "        for i in range(N):\n",
    "            s_i = s_range[i]\n",
    "\n",
    "            # select bottom s_i eigenvectors and calculate alpha\n",
    "            Vi = V[i, :, n_neighbors - s_i:]\n",
    "            alpha_i = np.linalg.norm(Vi.sum(0)) / np.sqrt(s_i)\n",
    "\n",
    "            # compute Householder matrix which satisfies\n",
    "            #  Hi*Vi.T*ones(n_neighbors) = alpha_i*ones(s)\n",
    "            # using prescription from paper\n",
    "            h = np.full(s_i, alpha_i) - np.dot(Vi.T, np.ones(n_neighbors))\n",
    "\n",
    "            norm_h = np.linalg.norm(h)\n",
    "            if norm_h < modified_tol:\n",
    "                h *= 0\n",
    "            else:\n",
    "                h /= norm_h\n",
    "\n",
    "            # Householder matrix is\n",
    "            #  >> Hi = np.identity(s_i) - 2*np.outer(h,h)\n",
    "            # Then the weight matrix is\n",
    "            #  >> Wi = np.dot(Vi,Hi) + (1-alpha_i) * w_reg[i,:,None]\n",
    "            # We do this much more efficiently:\n",
    "            Wi = (Vi - 2 * np.outer(np.dot(Vi, h), h) +\n",
    "                  (1 - alpha_i) * w_reg[i, :, None])\n",
    "\n",
    "            # Update M as follows:\n",
    "            # >> W_hat = np.zeros( (N,s_i) )\n",
    "            # >> W_hat[neighbors[i],:] = Wi\n",
    "            # >> W_hat[i] -= 1\n",
    "            # >> M += np.dot(W_hat,W_hat.T)\n",
    "            # We can do this much more efficiently:\n",
    "            nbrs_x, nbrs_y = np.meshgrid(neighbors[i], neighbors[i])\n",
    "            M[nbrs_x, nbrs_y] += np.dot(Wi, Wi.T)\n",
    "            Wi_sum1 = Wi.sum(1)\n",
    "            M[i, neighbors[i]] -= Wi_sum1\n",
    "            M[neighbors[i], i] -= Wi_sum1\n",
    "            M[i, i] += s_i\n",
    "\n",
    "        if M_sparse:\n",
    "            M = csr_matrix(M)\n",
    "\n",
    "    elif method == 'ltsa':\n",
    "        neighbors = nbrs.kneighbors(X, n_neighbors=n_neighbors + 1,\n",
    "                                    return_distance=False)\n",
    "        neighbors = neighbors[:, 1:]\n",
    "\n",
    "        M = np.zeros((N, N))\n",
    "\n",
    "        use_svd = (n_neighbors > d_in)\n",
    "\n",
    "        for i in range(N):\n",
    "            Xi = X[neighbors[i]]\n",
    "            Xi -= Xi.mean(0)\n",
    "\n",
    "            # compute n_components largest eigenvalues of Xi * Xi^T\n",
    "            if use_svd:\n",
    "                v = svd(Xi, full_matrices=True)[0]\n",
    "            else:\n",
    "                Ci = np.dot(Xi, Xi.T)\n",
    "                v = eigh(Ci)[1][:, ::-1]\n",
    "\n",
    "            Gi = np.zeros((n_neighbors, n_components + 1))\n",
    "            Gi[:, 1:] = v[:, :n_components]\n",
    "            Gi[:, 0] = 1. / np.sqrt(n_neighbors)\n",
    "\n",
    "            GiGiT = np.dot(Gi, Gi.T)\n",
    "\n",
    "            nbrs_x, nbrs_y = np.meshgrid(neighbors[i], neighbors[i])\n",
    "            M[nbrs_x, nbrs_y] -= GiGiT\n",
    "            M[neighbors[i], neighbors[i]] += 1\n",
    "    \n",
    "    return W\n",
    "    a,b = null_space(M, n_components, k_skip=1, eigen_solver=eigen_solver,\n",
    "                      tol=tol, max_iter=max_iter, random_state=random_state)\n",
    "    \n",
    "    #return a,b,W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
